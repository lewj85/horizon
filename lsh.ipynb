{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053721be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "from skimage.draw import line\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce741a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the fixed dem\n",
    "savefile = \"dems/brooklyn10mfixed.npy\"\n",
    "dem2 = np.load(savefile)\n",
    "print(dem2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# THRESHOLD TESTING\n",
    "################################\n",
    "\n",
    "window_size = 90\n",
    "bands = 45\n",
    "seed = 42\n",
    "\n",
    "# generate the thresholds\n",
    "random.seed(seed)\n",
    "thresholds = [random.random() for i in range(bands)] # instead of range(window_size)\n",
    "#thresholds = np.asarray(thresholds)\n",
    "#thresholds *= 0.8 # to leave wiggle room at the top since we're doing \"> threshold\"\n",
    "random.seed(seed)\n",
    "indices = random.sample(range(window_size), bands)\n",
    "\n",
    "plt.plot(thresholds)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766a50ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick more intelligent thresholds?\n",
    "# NOTE: don't rely on random indices either!\n",
    "\n",
    "fig = plt.figure(figsize=(20,6))\n",
    "x = range(0,90,2)\n",
    "\n",
    "evens = [0.2, 0.4, 0.6, 0.8]*(bands//4)\n",
    "evens += evens[:bands%4]\n",
    "#henc = np.where(h90norm[indices] > evens, 1, 0)\n",
    "#print(henc)\n",
    "plt.subplot(221)\n",
    "plt.plot(x,evens)\n",
    "plt.title(\"Evens\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "odds = [0.1, 0.3, 0.5, 0.7, 0.9]*(bands//5)\n",
    "odds += odds[:bands%5]\n",
    "plt.subplot(222)\n",
    "plt.plot(x,odds)\n",
    "plt.title(\"Odds\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# cut out 0.5, lose a little of the middle but capture the extremes\n",
    "t3 = [0.1, 0.3, 0.7, 0.9]*(bands//4)\n",
    "t3 += t3[:bands%4]\n",
    "plt.subplot(223)\n",
    "plt.plot(x,t3)\n",
    "plt.title(\"Odds minus 0.5\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# reorganize odds\n",
    "odds2 = [0.1, 0.7, 0.3, 0.9, 0.5]*(bands//5)\n",
    "odds2 += odds2[:bands%5]\n",
    "plt.subplot(224)\n",
    "plt.plot(x,odds2)\n",
    "plt.title(\"Odds reordered\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a247e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best of both worlds: focus on extremes and reorder\n",
    "odds3 = [0.1, 0.7, 0.3, 0.9]*(bands//4)\n",
    "odds3 += odds3[:bands%4]\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.subplot(121)\n",
    "plt.plot(x,odds3)\n",
    "plt.title(\"Odds minus 0.5 and reordered\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# as points\n",
    "odds3 = [0.1, 0.7, 0.3, 0.9]*(bands//4)\n",
    "odds3 += odds3[:bands%4]\n",
    "plt.subplot(122)\n",
    "plt.plot(x,odds3,\".\")\n",
    "plt.title(\"Odds minus 0.5 and reordered as points\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()\n",
    "\n",
    "# compared to original random thresholds\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.subplot(121)\n",
    "plt.plot(x,thresholds)\n",
    "plt.title(\"Random\")\n",
    "plt.ylim(0,1)\n",
    "\n",
    "# with correct indices\n",
    "plt.subplot(122)\n",
    "plt.plot(indices,thresholds,\".\")\n",
    "plt.title(\"Random with correct indices\")\n",
    "plt.ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11587203",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# CREATE THRESHOLDS/INDICES\n",
    "####################################\n",
    "# NOTE: if we lower bands, we have to keep similarity_threshold low too to filter out too many collisions\n",
    "window_size = 90\n",
    "bands = 45\n",
    "similarity_threshold = 0\n",
    "seed = 42\n",
    "assert bands <= window_size\n",
    "\n",
    "have_template = False # so we create the encoded horizon template later\n",
    "all_similar_matches = []\n",
    "\n",
    "# generate the thresholds and random indices once outside the loop\n",
    "random.seed(seed)\n",
    "thresholds = [random.random() for i in range(bands)] # instead of range(window_size)\n",
    "#thresholds = np.asarray(thresholds)\n",
    "#thresholds *= 0.8 # to leave wiggle room at the top since we're doing \"> threshold\"\n",
    "random.seed(seed)\n",
    "indices = random.sample(range(window_size), bands)\n",
    "\n",
    "####################################\n",
    "# select random points, collect all horizons, look for collisions\n",
    "num_points = 1000\n",
    "point_seed = 123\n",
    "random.seed(point_seed)\n",
    "####################################\n",
    "start_time = time.time()\n",
    "normalized_encoded_horizon_dict = {}\n",
    "nonnorm_nonencoded_horizon_dict = {}\n",
    "\n",
    "# pick num_points random points\n",
    "start_points = []\n",
    "for i in range(num_points):\n",
    "    row = random.randint(100,1300)\n",
    "    col = random.randint(100,1000)\n",
    "    new_point = [row,col]\n",
    "    while new_point in start_points:\n",
    "        row = random.randint(100,1300)\n",
    "        col = random.randint(100,1000)\n",
    "        new_point = [row,col]\n",
    "    start_points.append(new_point)\n",
    "\n",
    "for ii,start in enumerate(start_points):\n",
    "    ######################################\n",
    "    # GET HORIZON IN ALL 360 DIRECTIONS\n",
    "    ######################################\n",
    "    #start = [600, 600]\n",
    "    print(ii, start)\n",
    "    horizon_locations = []\n",
    "    horizon_elevations = []\n",
    "    horizon_thetas = []\n",
    "    angle_step_size = 1\n",
    "\n",
    "    # get horizon at every X degrees around our centerpoint\n",
    "    for direction in range(0, int(360/angle_step_size), 1): # use division instead of 3rd range() param for step\n",
    "                                                            # so we can use fraction step sizes like 0.5 degrees\n",
    "        direction *= angle_step_size\n",
    "#         if direction%45==0:\n",
    "#             print(direction)\n",
    "        radians = np.deg2rad(direction)\n",
    "\n",
    "        # adjust opp and adj depending on quadrant of the angle\n",
    "        if direction >= 0 and direction < 90:\n",
    "            adj = dem2.shape[1]-start[1]\n",
    "            opp = np.tan(radians)*adj\n",
    "        elif direction > 90 and direction < 180:\n",
    "            adj = -start[1]\n",
    "            opp = np.tan(radians)*adj\n",
    "        elif direction >= 180 and direction < 270:\n",
    "            adj = -start[1]\n",
    "            opp = np.tan(radians)*adj\n",
    "        elif direction > 270: # and direction < 360:\n",
    "            adj = dem2.shape[1]-start[1]\n",
    "            opp = np.tan(radians)*adj\n",
    "        elif direction == 90: # tan(90 degrees) is infinity\n",
    "            adj = 0\n",
    "            opp = start[0]\n",
    "        elif direction == 270: # tan(270 degrees) is infinity\n",
    "            adj = 0\n",
    "            opp = start[0]-dem2.shape[0]\n",
    "\n",
    "        #https://stackoverflow.com/questions/7878398/how-to-extract-an-arbitrary-line-of-values-from-a-numpy-array\n",
    "        #https://en.wikipedia.org/wiki/Bresenham%27s_line_algorithm\n",
    "        # can switch below to skimage.draw.line() for fast rows/cols. can use line_aa() for anti-aliasing to make less jagged.\n",
    "\n",
    "        # make a line with \"num\" points...\n",
    "        x0, y0 = start[1], start[0] # these are in pixel coordinates\n",
    "        x1, y1 = start[1]+adj, start[0]-opp # NOTE: y values are reversed because rows start at the top\n",
    "        num = int(np.hypot(x1-x0, y1-y0)) # approx num of pixels from point to edge of image\n",
    "        x, y = np.linspace(x0, x1, num), np.linspace(y0, y1, num)\n",
    "\n",
    "        # check for out of bounds before mapping\n",
    "        indx = 0\n",
    "        while indx < len(x):\n",
    "            if x[indx] < 0 or x[indx] >= dem2.shape[1]:\n",
    "                break\n",
    "            else:\n",
    "                indx += 1\n",
    "        indy = 0\n",
    "        while indy < len(y):\n",
    "            if y[indy] < 0 or y[indy] >= dem2.shape[0]:\n",
    "                break\n",
    "            else:\n",
    "                indy += 1\n",
    "        # always take the smaller to stay inside the dem array\n",
    "        if indx <= indy:\n",
    "            x = x[:indx]\n",
    "            y = y[:indx]\n",
    "        else:\n",
    "            x = x[:indy]\n",
    "            y = y[:indy]\n",
    "\n",
    "        # now map!\n",
    "        zi = scipy.ndimage.map_coordinates(dem2, np.vstack((y,x)))\n",
    "\n",
    "        # initialize values before loop\n",
    "        start_elev = dem2[start[0], start[1]] + 2 # start 2m higher to prevent small changes from nearby pixels having\n",
    "                                                  # the highest thetas, plus many images are taken at eye level\n",
    "        maxtheta = -np.pi/4 # lowest possible = 90 degrees down\n",
    "        highest_location = start.copy()\n",
    "        highest_elevation = -999999.\n",
    "\n",
    "        # go through each value along the hypotenuse zi\n",
    "        for dist_along_hypot,elev in enumerate(zi):\n",
    "            if dist_along_hypot > 0: # skip the first value bc that's where we're starting from\n",
    "\n",
    "                # adjacent length is 10m per pixel, which is 10x height, so multiply col by 10 to match height ratio\n",
    "                # NOTE: adjacent pixel gsd is arbitrary so could skip multiplying by 10. yes, all angles will be off,\n",
    "                #       but they will be off proportionately! and all we need is where the biggest angle is anyway.\n",
    "                #       we don't need that biggest angle to be accurate (at least for now...)\n",
    "                # NOTE: keeping the multiplication by 10 though because we need an accurate adj value for the opp formula!\n",
    "                adj = dist_along_hypot*10\n",
    "\n",
    "                # subtract start_elev to normalize all other elevations\n",
    "                # also, subtract 8 inches per mile according to https://www.omnicalculator.com/physics/earth-curvature\n",
    "                # 8 inches = 0.2032 meters, 1 mile = 1609.34 meters\n",
    "                opp = elev - start_elev - (adj*0.2032/1609.34)\n",
    "\n",
    "                # find theta with arctan(opposite/adjacent)\n",
    "                newtheta = np.arctan(opp/adj)\n",
    "\n",
    "                # biggest angle is the horizon\n",
    "                if newtheta > maxtheta:\n",
    "                    maxtheta = newtheta\n",
    "                    # calc row and col position given angle and hypotenuse. SOHCAHTOA\n",
    "                    rows_above_start = np.sin(radians)*dist_along_hypot\n",
    "                    cols_right_of_start = np.cos(radians)*dist_along_hypot\n",
    "                    highest_location = [start[0]-rows_above_start, start[1]+cols_right_of_start]\n",
    "                    highest_elevation = elev\n",
    "\n",
    "        # store horizon values\n",
    "        horizon_locations.append(highest_location)\n",
    "        horizon_elevations.append(highest_elevation)\n",
    "        horizon_thetas.append(maxtheta)\n",
    "    \n",
    "#     ###############################\n",
    "#     # GRAPH FULL 360 HORIZON\n",
    "#     ###############################\n",
    "#     rows, cols = zip(*horizon_locations)\n",
    "\n",
    "#     fig = plt.figure(figsize=(15, 15))\n",
    "\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     ax.set_title('Horizon Overlay')\n",
    "#     plt.imshow(dem2)\n",
    "#     for i in range(len(cols)):\n",
    "#         rows2 = [start[0], rows[i]]\n",
    "#         cols2 = [start[1], cols[i]]\n",
    "#         plt.plot(cols2, rows2, 'r-')\n",
    "#         #plt.plot(start[1], start[0], 'ro') # NOTE: expects x,y not row,col so reverse them\n",
    "#         #plt.plot(cols,rows, 'rx-') # NOTE: expects x,y not row,col so reverse them\n",
    "\n",
    "#     # start point in green\n",
    "#     plt.plot([start[1]], [start[0]], 'go', markersize=8)\n",
    "\n",
    "#     ax.set_aspect('equal')\n",
    "#     cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])\n",
    "#     cax.get_xaxis().set_visible(False)\n",
    "#     cax.get_yaxis().set_visible(False)\n",
    "#     cax.patch.set_alpha(0)\n",
    "#     cax.set_frame_on(False)\n",
    "#     plt.colorbar(orientation='vertical', ax=ax)\n",
    "#     plt.show()\n",
    "    \n",
    "    # so use horizon_thetas instead and use opp = tan()*adj with a set adjacent length\n",
    "    adj = 1 # this value doesn't matter if we are normalizing both our template and each subsection in the sliding window\n",
    "    h2 = [adj*np.tan(x) for x in horizon_thetas] # can remove multiplying by adj altogether bc of above comment\n",
    "    h2.reverse()\n",
    "\n",
    "#     fig2, ax2 = plt.subplots(figsize=(20,5))\n",
    "#     plt.subplot(212)\n",
    "#     plt.plot(h2)\n",
    "#     #plt.ylim(0,100)\n",
    "#     for key,value in cardinals.items():\n",
    "#         plt.vlines(x=key, ymin=min(h2), ymax=0.8*max(h2), colors='purple', label=value, linestyle='dashed')\n",
    "#         plt.annotate(text=value, xy=(key, 0.9*max(h2)), xytext=(key, 0.9*max(h2)), ha=\"center\")\n",
    "#     plt.title(\"Horizon\")\n",
    "#     plt.show()\n",
    "    \n",
    "    ###########################################\n",
    "    # CREATE TEMPLATE (if we haven't already)\n",
    "    ###########################################\n",
    "    # create template once\n",
    "    if not have_template:\n",
    "        # get first 90 degree section for template\n",
    "        h90 = h2[0:90]\n",
    "        # normalize it\n",
    "        h90norm = (h90 - np.min(h90)) / (np.max(h90) - np.min(h90))\n",
    "        henc2 = np.where(h90norm[indices] > thresholds, 1, 0)\n",
    "        have_template = True\n",
    "\n",
    "    #########################################\n",
    "    # COMPARE TEMPLATE TO HORIZON\n",
    "    #########################################\n",
    "    # test encoding in all 360 degrees\n",
    "    similar_horizon_starting_points = []\n",
    "    diffs = []\n",
    "    for start_ind in range(360):\n",
    "        # get values from horizon\n",
    "        if start_ind+window_size > 360:\n",
    "            h90 = h2[start_ind:]\n",
    "            h90 += h2[:window_size-len(h90)]\n",
    "        else:\n",
    "            h90 = h2[start_ind:start_ind+window_size]\n",
    "\n",
    "        # normalize it\n",
    "        h90norm = (h90 - np.min(h90)) / (np.max(h90) - np.min(h90))\n",
    "        h90norm = np.asarray(h90norm)\n",
    "\n",
    "        # apply thresholds\n",
    "        henc3 = np.where(h90norm[indices] > thresholds, 1, 0)\n",
    "        \n",
    "        ###############################\n",
    "        # ADD TO DICT FOR JSON LATER\n",
    "        ###############################\n",
    "        key = \"\"\n",
    "        for zero_or_one in henc3:\n",
    "            key += str(zero_or_one)\n",
    "        #print(\"key\", key)\n",
    "        if not normalized_encoded_horizon_dict.get(key, False):\n",
    "            normalized_encoded_horizon_dict[key] = []\n",
    "        normalized_encoded_horizon_dict[key].append([start, start_ind])\n",
    "\n",
    "    # add nonnorm nonencoded original horizon to dict so we can quickly look up horizons\n",
    "    #    for each start point\n",
    "    startstr = str(start)\n",
    "    nonnorm_nonencoded_horizon_dict[startstr] = h2\n",
    "\n",
    "#         # if difference is small enough between horizons, keep it\n",
    "#         thediff = sum(np.abs(henc3-henc2))\n",
    "#         if thediff <= similarity_threshold:\n",
    "#             similar_horizon_starting_points.append(start_ind)\n",
    "#             diffs.append(thediff)\n",
    "#             all_similar_matches.append([start, start_ind])\n",
    "\n",
    "#     print(\"similar_horizon_starting_points\", similar_horizon_starting_points)\n",
    "#     print(\"diffs\", diffs)\n",
    "    \n",
    "#     ################################\n",
    "#     # SHOW SIMILAR HORIZONS\n",
    "#     ################################\n",
    "#     if len(similar_horizon_starting_points):\n",
    "#         ncols = 4\n",
    "#         extrarow = 1 if len(similar_horizon_starting_points)%ncols > 0 else 0\n",
    "#         nrows = len(similar_horizon_starting_points)//ncols + extrarow\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(20,2*nrows))\n",
    "\n",
    "#         for i,start_ind in enumerate(similar_horizon_starting_points):\n",
    "#             # get values from horizon\n",
    "#             if start_ind+window_size > 360:\n",
    "#                 h90 = h2[start_ind:]\n",
    "#                 h90 += h2[:window_size-len(h90)]\n",
    "#             else:\n",
    "#                 h90 = h2[start_ind:start_ind+window_size]\n",
    "\n",
    "#             # normalize it\n",
    "#             h90norm = (h90 - np.min(h90)) / (np.max(h90) - np.min(h90))\n",
    "\n",
    "#             # plot it\n",
    "#             plt.subplot(nrows, ncols, i+1)\n",
    "#             plt.title(str(start_ind))\n",
    "#             plt.plot(h90norm)\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"No similar horizons for\", start)\n",
    "\n",
    "print(\"Done!\")\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = end_time - start_time\n",
    "print(round(total_time/60//60), \"hours\", round(total_time/60%60), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5192707",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# DUMP INTO JSONS\n",
    "##################\n",
    "filename = \"dicts/normalized_encoded_horizon_dict_window\"+str(window_size)+\"_bands\"+str(bands)+\"_simthresh\"+str(similarity_threshold)+\"_random_seed\"+str(seed)+\".json\"\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(normalized_encoded_horizon_dict, f)\n",
    "\n",
    "filename = \"dicts/nonnorm_nonencoded_horizon_dict_numpoints\"+str(num_points)+\"_pointseed\"+str(point_seed)+\".json\"\n",
    "with open(filename, \"w\") as f:\n",
    "    json.dump(nonnorm_nonencoded_horizon_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192afd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################\n",
    "# LOAD JSON\n",
    "##################\n",
    "filename = \"dicts/normalized_encoded_horizon_dict.json\"\n",
    "with open(filename) as f:\n",
    "    normalized_encoded_horizon_dict = json.load(f)\n",
    "    for k,v in normalized_encoded_horizon_dict.items():\n",
    "        print(k,v)\n",
    "        break\n",
    "\n",
    "filename = \"dicts/nonnorm_nonencoded_horizon_dict.json\"\n",
    "with open(filename) as f:\n",
    "    nonnorm_nonencoded_horizon_dict = json.load(f)\n",
    "    for p,h2 in nonnorm_nonencoded_horizon_dict.items():\n",
    "        print(p,h2)\n",
    "        break\n",
    "\n",
    "fig = plt.figure(figsize=(20,2))\n",
    "plt.plot(h2)\n",
    "#plt.ylim(0,100)\n",
    "for key,value in cardinals.items():\n",
    "    plt.vlines(x=key, ymin=min(h2), ymax=0.8*max(h2), colors='purple', label=value, linestyle='dashed')\n",
    "    plt.annotate(text=value, xy=(key, 0.9*max(h2)), xytext=(key, 0.9*max(h2)), ha=\"center\")\n",
    "plt.title(\"Horizon\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f1aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot points with similar horizons to find clusters\n",
    "points = [p for p,d in v]\n",
    "x = [x for y,x in points]\n",
    "y = [y for y,x in points]\n",
    "fig = plt.figure(figsize=(4,5))\n",
    "plt.plot(x,y, \".\")\n",
    "plt.xlim(0,1073)\n",
    "plt.ylim(0,1403)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5abf955",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(normalized_encoded_horizon_dict.items()))\n",
    "print(len(nonnorm_nonencoded_horizon_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed895be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine all horizon collisions from the first item in normalized_encoded_horizon_dict\n",
    "for horizon_encoding,similar_horizon_starting_points in normalized_encoded_horizon_dict.items():\n",
    "    print(horizon_encoding,similar_horizon_starting_points)\n",
    "    break\n",
    "\n",
    "window_size = 90\n",
    "ncols = 4\n",
    "extrarow = 1 if len(similar_horizon_starting_points)%ncols > 0 else 0\n",
    "nrows = len(similar_horizon_starting_points)//ncols + extrarow\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,2.5*nrows))\n",
    "\n",
    "for i,start_ind in enumerate(similar_horizon_starting_points):\n",
    "    print(start_ind)\n",
    "    h2 = nonnorm_nonencoded_horizon_dict[str(start_ind[0])]\n",
    "\n",
    "    # get values from horizon\n",
    "    if start_ind[1]+window_size > 360:\n",
    "        h90 = h2[start_ind[1]:]\n",
    "        h90 += h2[:window_size-len(h90)]\n",
    "    else:\n",
    "        h90 = h2[start_ind[1]:start_ind[1]+window_size]\n",
    "\n",
    "    # normalize it\n",
    "    h90norm = (h90 - np.min(h90)) / (np.max(h90) - np.min(h90))\n",
    "\n",
    "    # plot it\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "    plt.title(str(start_ind))\n",
    "    plt.plot(h90norm)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
